# Sets the the default model to use for llm() when no provider parameter is set.

cfg-yaml:
  model:
    provider: openai
    parameters:
      api_key: null

  # list of supported providers.
  providers:
    openai:
      name: OpenAI
      description: OpenAI's and AzureOpenAI GPT-3 and GPT-4 models
      models:
        # - name: gpt-3.5-turbo-0301
        #   max_tokens: 4096
        #   model:
        #     provider: openai
        #     parameters:
        #       model: gpt-3.5-turbo-0301
        - name: gpt-4o # general model name, can be anything
          max_tokens: 4096 # max supported tokens
          model:
            provider: openai
            parameters:
              model: gpt-4o 
    anthropic:
      name: Anthropic
      description: Anthropic's Claude models
      models:
        - name: claude-3-5-sonnet-20240620
          max_tokens: 8192
          model:
            provider: anthropic
            parameters:
              model: claude-3-5-sonnet-20240620
